{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2 Part 1 - Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment, you will implement a decision tree model.\n",
    "\n",
    "*For Even Roll Number Students:*\n",
    "\n",
    "* In this part, you have to implement a decision tree model to predict the cardio vascular disease based on various input features.\n",
    "* Noiseless Dataset: ````cardio.csv````\n",
    "* Noisy Dataset: ````cardio_noise.csv````\n",
    "\n",
    "*For Odd Roll Number Students:*\n",
    "\n",
    "* In this part, you have to implement a decision tree model to predict whether a patient has diabetes based on various input features.\n",
    "* Noiseless Dataset: ````diabetes.csv````\n",
    "* Noisy Dataset: ````diabetes_noise.csv````\n",
    "\n",
    "The assignment zip file (ML_CS60050_A2.zip) contains the respective datasets which will be used in this assignment.\n",
    "\n",
    "You have to write your code in this jupyter notebook. You have to write your code only between ### START CODE HERE ### and ### END CODE HERE ### comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Submission Instructions\n",
    "\n",
    "Please submit your assignment as a ZIP file that contains a folder named in the following format: `RollNo_ML_A2`. Inside this folder, include two Jupyter notebooks and a Report with the following names:\n",
    "\n",
    "1. `RollNo_A2_Part1.ipynb`\n",
    "2. `RollNo_A2_Part2.ipynb`\n",
    "3. `RollNo_report.pdf`\n",
    "\n",
    "\n",
    "Instructions for the Report:\n",
    "* Summarize results from noiseless and noisy datasets.\n",
    "* Compare performance and note the impact of noise.\n",
    "* Conclude with key findings andÂ implications.\n",
    "\n",
    "Make sure that you replace `RollNo` with your actual roll number in both the folder name and the notebook filenames.\n",
    "\n",
    "For example, if your roll number is `23CS60R11`, the folder should be named `23CS60R11_ML_A2`, and the three files should be named `23CS60R11_A2_Part1.ipynb`, `23CS60R11_A2_Part2.ipynb` and `RollNo_report.pdf`.\n",
    "\n",
    "Submit this ZIP file as your assignment submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/trilochan1016/.local/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /home/trilochan1016/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: seaborn in /home/trilochan1016/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/trilochan1016/.local/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/trilochan1016/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/trilochan1016/.local/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/trilochan1016/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/trilochan1016/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/trilochan1016/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/trilochan1016/.local/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/trilochan1016/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipython in /home/trilochan1016/.local/lib/python3.10/site-packages (8.22.2)\n",
      "Requirement already satisfied: decorator in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (5.14.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/trilochan1016/.local/lib/python3.10/site-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/trilochan1016/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/trilochan1016/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/trilochan1016/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from stack-data->ipython) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/trilochan1016/.local/lib/python3.10/site-packages (from stack-data->ipython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/trilochan1016/.local/lib/python3.10/site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pygraphviz in /home/trilochan1016/.local/lib/python3.10/site-packages (1.13)\n"
     ]
    }
   ],
   "source": [
    "# Install pandas, numpy, seaborn, and matplotlib\n",
    "! pip install pandas numpy seaborn matplotlib\n",
    "\n",
    "# Install scikit-learn\n",
    "! pip install scikit-learn\n",
    "\n",
    "# Install IPython\n",
    "! pip install ipython\n",
    "\n",
    "# Install pygraphviz\n",
    "! pip install pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the instructions given in the file ````graphviz_installation.txt```` to install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from graphviz import Digraph\n",
    "from IPython.display import Image, display\n",
    "import pygraphviz as pgv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cardio_noise.csv') # Replace with noise/noiseless dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train, Validation, Test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7680, 12), (2400, 12), (1920, 12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df,test_df = train_test_split(df,test_size=0.2,random_state=1)\n",
    "train_df,val_df = train_test_split(train_df,test_size=0.2,random_state=1)\n",
    "train_df.shape,test_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the algorithm works\n",
    "\n",
    "**We'll start with all examples at the root node then:**\n",
    "\n",
    "**We'll calculate information gain for splitting on all possible features and pick the one with the highest value**\n",
    "\n",
    "**Then we'll split the data according to the selected feature**\n",
    "\n",
    "**We'll repeat this  process until stopping criteria is met**\n",
    "\n",
    "## Key Points:\n",
    "\n",
    "### Entropy\n",
    "**Entropy function which is a way to measure impurity**\n",
    "\n",
    "**Entropy is represented by this function**\n",
    "$$H = -\\sum\\limits_{}^{} p_{i}\\text{log}_2 p_{i} \n",
    "$$\n",
    "\n",
    "**Where $(p_1)$ is the fraction of examples that are a certain class**\n",
    "\n",
    "\n",
    "### Information Gain\n",
    "\n",
    "**Information gain is the reduction in entropy when he make a split**\n",
    "\n",
    "**Recall that our goal is to choose the split that gives the highest information gain, information gain equation =**\n",
    "\n",
    "**$$H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$**\n",
    "**where** \n",
    "- $H(p_1^\\text{node})$ is entropy at the node \n",
    "- $H(p_1^\\text{left})$ and $H(p_1^\\text{right})$ are the entropies at the left and the right branches resulting from the split\n",
    "- $w^{\\text{left}}$ and $w^{\\text{right}}$ are the proportion of examples at the left and right branch respectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree visualization using graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pgv.AGraph(strict=True, directed=True)\n",
    "graph2 = pgv.AGraph(strict=True, directed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root = Node(None)\n",
    "        self.height = -1\n",
    "\n",
    "    def find_splits(self, data, column_index):\n",
    "        \"\"\"\n",
    "        Identifies potential split points for a given feature.\n",
    "        \n",
    "        Parameters:\n",
    "            data (numpy.ndarray): The dataset used for finding splits.\n",
    "            column_index (int): The index of the column for which to find potential splits.\n",
    "        \n",
    "        Returns:\n",
    "            potential_splits (list): A list of potential split points for the specified feature.\n",
    "        \"\"\"\n",
    "\n",
    "        x = data[:,:-1]\n",
    "        potential_splits = []\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        feature_values = x.iloc[:, column_index]\n",
    "        # CODE HERE (REFER LECTURE SLIDES)\n",
    "        unique_values = feature_values.unique()  \n",
    "        unique_values.sort()  \n",
    "        \n",
    "        if len(unique_values) > 1:\n",
    "            for i in range(len(unique_values) - 1):\n",
    "                split_point = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "                potential_splits.append(split_point)\n",
    "                \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return potential_splits\n",
    "\n",
    "\n",
    "    def calculate_entropy(self, data):\n",
    "        \"\"\"\n",
    "        Calculates the entropy of the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            data (numpy.ndarray): The dataset for which to calculate entropy.\n",
    "        \n",
    "        Returns:\n",
    "            entropy (float): The entropy value of the dataset.\n",
    "        \"\"\"\n",
    "        y = data[:, -1]\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        ### START CODE HERE ###\n",
    "        #entropy = None # Replace with actual code\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        ### END CODE HERE ###\n",
    "        return entropy\n",
    "\n",
    "    def calculate_information_gain(self, data, column_no, value):\n",
    "        \"\"\"\n",
    "        Calculates the information gain resulting from splitting the data on a specific feature at a specific value.\n",
    "        \n",
    "        Parameters:\n",
    "            data (numpy.ndarray): The dataset to split.\n",
    "            column_no (int): The index of the feature used to split the data.\n",
    "            value (float): The value at which to split the feature.\n",
    "        \n",
    "        Returns:\n",
    "            information_gain (float): The information gain from the split.\n",
    "        \"\"\"\n",
    "        parent_entropy = self.calculate_entropy(data)\n",
    "        left_data = data[data[:, column_no] <= value]\n",
    "        right_data = data[data[:, column_no] > value]\n",
    "\n",
    "        n = len(left_data) + len(right_data)\n",
    "        p_left_data = len(left_data) / n\n",
    "        p_right_data = len(right_data) / n\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        #child_entropy = None  # Replace with actual code\n",
    "        \n",
    "        child_entropy = (p_left_data * self.calculate_entropy(left_data)) + (p_right_data * self.calculate_entropy(right_data))\n",
    "        \n",
    "        #information_gain = None  # Replace with actual code\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return information_gain\n",
    "\n",
    "    def majority(self, data):\n",
    "        \"\"\"\n",
    "        Determines the majority class label in the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            data (pandas.DataFrame): The dataset to classify.\n",
    "        \n",
    "        Returns:\n",
    "            majority_class (int): The label of the majority class.\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        cls, count = np.unique(data[\"cardio\"], return_counts=True) #Replace target with actual target attribute\n",
    "        if len(cls) == 0:\n",
    "            return None\n",
    "        ### END CODE HERE ###\n",
    "        return cls[np.argmax(count)]\n",
    "\n",
    "    def classify(self, data, edge):\n",
    "        \"\"\"\n",
    "        Classifies a dataset as a leaf node.\n",
    "        \n",
    "        Parameters:\n",
    "            data (pandas.DataFrame): The dataset to classify.\n",
    "            edge (int): The index of the parent edge.\n",
    "        \n",
    "        Returns:\n",
    "            leaf (Node): A leaf node with classification information.\n",
    "        \"\"\"\n",
    "        classification = self.majority(data)\n",
    "        entropy = self.calculate_entropy(data.values)\n",
    "        d = {\"ID\": \"Leaf\", \"Classification\": classification, \"Parent_Edge\": edge, \"Entropy\": entropy, \"Samples\": data.shape[0]}\n",
    "        leaf = Node(d)\n",
    "        return leaf\n",
    "    \n",
    "    def build_tree(self, data, max_depth, attributes, edge, height):\n",
    "        \"\"\"\n",
    "        A recursive utility function for building the decision tree.\n",
    "        \n",
    "        Parameters:\n",
    "            data (pandas.DataFrame): The dataset to build the tree from.\n",
    "            max_depth (int): The maximum allowed depth of the tree.\n",
    "            attributes (list): The list of attributes used in the dataset.\n",
    "            edge (int): The index of the parent edge.\n",
    "            height (int): The current height of the tree.\n",
    "        \n",
    "        Returns:\n",
    "            node (Node): The root node of the subtree created.\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### \n",
    "        if data.empty:\n",
    "            return Node({\"ID\": \"Leaf\", \"Classification\": None, \"Parent_Edge\": edge, \"Entropy\": 0, \"Samples\": 0})\n",
    "\n",
    "        # CODE HERE ... Implement the logic to extract the leaf node\n",
    "        if height >= max_depth or len(attributes) == 0 or len(np.unique(data[\"cardio\"])) == 1:\n",
    "            return self.classify(data, edge)\n",
    "            #return leaf\n",
    "            \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        \n",
    "        best = {\"ID\": \"\", \"best_attribute\": \"\", \"best_gain\": -1, \"best_split\": -1, \"best_entropy\": -1}\n",
    "\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # CODE TO EXTRACT THE BEST ATTRIBUTE AND STORE IT IN best VARIABLE\n",
    "        for attribute in attributes:\n",
    "            unique_values = np.unique(data[attribute]) \n",
    "            for value in unique_values:\n",
    "                gain = self.calculate_information_gain(data.values, data.columns.get_loc(attribute), value)\n",
    "                if gain > best[\"best_gain\"]:\n",
    "                    best[\"best_attribute\"] = attribute\n",
    "                    best[\"best_gain\"] = gain\n",
    "                    best[\"best_split\"] = value\n",
    "                    best[\"best_entropy\"] = self.calculate_entropy(data.values)          \n",
    "        ### END HERE ###\n",
    "\n",
    "        _, sample = np.unique(data[\"cardio\"], return_counts=True)\n",
    "        d = {\"ID\": best[\"best_attribute\"], \"Entropy\": best[\"best_entropy\"], \n",
    "             \"Samples\": data.shape[0], \"Parent_Edge\": edge, \n",
    "             \"Best_Split\": best[\"best_split\"], \"Values\": sample}\n",
    "        node = Node(d)\n",
    "        node.left = self.build_tree(data[data[best[\"best_attribute\"]] <= best[\"best_split\"]], max_depth, attributes, 2 * edge + 1, height + 1)\n",
    "        node.right = self.build_tree(data[data[best[\"best_attribute\"]] > best[\"best_split\"]], max_depth, attributes, 2 * edge + 2, height + 1)\n",
    "\n",
    "        root = f'{d[\"ID\"]} <= {d[\"Best_Split\"]}\\nEntropy = {d[\"Entropy\"]}\\nSamples = {d[\"Samples\"]}\\nValues = {sample}'\n",
    "        \n",
    "        graph.add_node(str(edge), label=root)\n",
    "        graph.add_edge(str(edge), str(2 * edge + 1))\n",
    "        graph.add_edge(str(edge), str(2 * edge + 2))\n",
    "        return node\n",
    "\n",
    "    def fit(self, data, max_depth=100):\n",
    "        \"\"\"\n",
    "        Fits the decision tree model to the provided dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            data (pandas.DataFrame): The dataset to fit the tree to.\n",
    "            max_depth (int): The maximum allowed depth of the tree.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        attributes = data.columns.tolist()[:-1]\n",
    "        self.attributes = np.array(attributes)\n",
    "        self.root = self.build_tree(data, max_depth, attributes, 0, 0)\n",
    "        \n",
    "    def plt(self, graph, node, vert):\n",
    "        \"\"\"\n",
    "        Plots the decision tree using a graph representation.\n",
    "        \n",
    "        Parameters:\n",
    "            graph (Graph): The graph object to use for plotting.\n",
    "            node (Node): The current node in the tree.\n",
    "            vert (int): The current vertex in the graph.\n",
    "        \n",
    "        Returns:\n",
    "            root (str): The label of the current node.\n",
    "        \"\"\"\n",
    "        d = node.data\n",
    "        if \"Classification\" in node.data.keys():\n",
    "            root = f'{d[\"ID\"]}\\nEntropy = {d[\"Entropy\"]}\\nSamples = {d[\"Samples\"]}\\nClass = {d[\"Classification\"]}'\n",
    "            graph.add_node(str(vert), label=root)\n",
    "            return root\n",
    "        \n",
    "        root = f'{d[\"ID\"]} <= {d[\"Best_Split\"]}\\nEntropy = {d[\"Entropy\"]}\\nSamples = {d[\"Samples\"]}\\nValues = {d[\"Values\"]}'\n",
    "        graph.add_node(str(vert), label=root)\n",
    "        root1 = self.plt(graph, node.left, 2 * vert + 1)\n",
    "        graph.add_node(str(2 * vert + 1), label=root1)\n",
    "        root2 = self.plt(graph, node.right, 2 * vert + 2)\n",
    "        graph.add_node(str(2 * vert + 2), label=root2)\n",
    "        \n",
    "        graph.add_edge(str(vert), str(2 * vert + 1))\n",
    "        graph.add_edge(str(vert), str(2 * vert + 2))\n",
    "        return root\n",
    "\n",
    "    def prune_util(self, node):\n",
    "        \"\"\"\n",
    "        Utility function for pruning a node in the decision tree.\n",
    "        \n",
    "        Parameters:\n",
    "            node (Node): The node to prune.\n",
    "        \n",
    "        Returns:\n",
    "            d (dict): The data for the pruned leaf node.\n",
    "        \"\"\"\n",
    "        d = {\"ID\": \"Leaf\", \"Classification\": 0, \"Parent_Edge\": node.data[\"Parent_Edge\"], \n",
    "             \"Entropy\": 0, \"Samples\": node.data[\"Samples\"]}\n",
    "        if node.data[\"Values\"][0] > node.data[\"Values\"][1]:\n",
    "            d[\"Classification\"] = 0\n",
    "        else:\n",
    "            d[\"Classification\"] = 1\n",
    "        return d\n",
    "        \n",
    "    def prune(self, val_df, node):\n",
    "        \"\"\"\n",
    "        Prunes the decision tree to avoid overfitting.\n",
    "        \n",
    "        Parameters:\n",
    "            val_df (pandas.DataFrame): The validation dataset used to evaluate pruning.\n",
    "            node (Node): The current node to consider pruning.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if \"Classification\" in node.data.keys():\n",
    "            return\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # RECURSIVE CALLS TO IT'S CHILDREN\n",
    "        if node.left:\n",
    "            self.prune(val_df, node.left)\n",
    "        if node.right:\n",
    "            self.prune(val_df, node.right)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        curr_val = accuracy_score(val_df.values[:, -1], self.predict(val_df.values[:, :-1]))\n",
    "\n",
    "        tmp1 = node.left\n",
    "        tmp2 = node.right\n",
    "        tmp = node.data\n",
    "        node.left = None\n",
    "        node.right = None\n",
    "\n",
    "        node.data = self.prune_util(node)\n",
    "\n",
    "        new_val = accuracy_score(val_df.values[:, -1], self.predict(val_df.values[:, :-1]))\n",
    "\n",
    "        # Decide whether to keep the pruning or revert to the original node\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Implement the decision logic for keeping or reverting pruning\n",
    "        if new_val < curr_val:\n",
    "            node.left = tmp1\n",
    "            node.right = tmp2\n",
    "            node.data = tmp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def predict_one(self, data):\n",
    "        \"\"\"\n",
    "        Predicts the class label for a single data point.\n",
    "        \n",
    "        Parameters:\n",
    "            data (numpy.ndarray): The data point to classify.\n",
    "        \n",
    "        Returns:\n",
    "            classification (int): The predicted class label.\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        while \"Classification\" not in node.data.keys():\n",
    "            d = node.data\n",
    "            if data[np.argwhere(self.attributes == d[\"ID\"]).squeeze()] <= d[\"Best_Split\"]:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.data[\"Classification\"]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for a dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            X (numpy.ndarray): The dataset to classify.\n",
    "        \n",
    "        Returns:\n",
    "            Y_pred (numpy.ndarray): The predicted class labels.\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        Y_pred = np.zeros(X.shape[0], dtype=int)\n",
    "        for i in range(X.shape[0]):\n",
    "            Y_pred[i] = self.predict_one(X[i])\n",
    "        return Y_pred\n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()\n",
    "model.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Decision Tree before Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.draw(\"Decision_Tree_Before_Pruning.png\", prog=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='Decision_Tree_Before_Pruning.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing before Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.values[:,:-1]\n",
    "Y_test = test_df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy,Macro Precision, Macro Recall Before Pruning\")\n",
    "accuracy_score(Y_test,Y_pred),precision_score(Y_test,Y_pred,average='macro'),recall_score(Y_test,Y_pred,average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Error Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prune(val_df,model.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ =model.plt(graph2,model.root,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2.draw(\"Decision_Tree_After_Pruning.png\", prog=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='Decision_Tree_After_Pruning.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing after Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(\"Accuracy,Macro Precision, Macro Recall After Pruning\")\n",
    "accuracy_score(Y_test,Y_pred),precision_score(Y_test,Y_pred,average='macro'),recall_score(Y_test,Y_pred,average = 'macro')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1829286,
     "sourceId": 2984728,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30260,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
